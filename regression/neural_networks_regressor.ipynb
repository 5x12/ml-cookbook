{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning Algorithms: Neural Networks - Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*In this template, only **data input** and **input/target variables** need to be specified (see \"Data Input & Variables\" section for further instructions). None of the other sections needs to be adjusted. As a data input example, .csv file from IBM Box web repository is used.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Run to import the required libraries.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Input and Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Define the data input as well as the input (X) and target (y) variables and run the code. Do not change the data & variable names **['df', 'X', 'y']** as they are used in further sections.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Input\n",
    "# df = \n",
    "\n",
    "### Defining Variables  \n",
    "# X = \n",
    "# y = \n",
    "\n",
    "### Data Input Example \n",
    "df = pd.read_csv('https://ibm.box.com/shared/static/q6iiqb1pd7wo8r3q28jvgsrprzezjqk3.csv')\n",
    "\n",
    "X = df[['horsepower', 'normalized-losses']]\n",
    "y = df['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of NN classifier on training set: 0.65\n",
      "Accuracy of NN classifier on test set: 0.68\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# normalized\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# model \n",
    "clf = MLPRegressor(hidden_layer_sizes = [100, 100], alpha = 5.0, random_state = 0, solver='lbfgs').fit(X_train_scaled, y_train)\n",
    "\n",
    "print('Accuracy of NN regressor on training set: {:.2f}'\n",
    "     .format(clf.score(X_train_scaled, y_train)))\n",
    "print('Accuracy of NN regressor on test set: {:.2f}'\n",
    "     .format(clf.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Accuracy with different activation functions and regularization parameter alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of NN regressor with activation funtion = tanh and alpha = 0.0001 on training set: 0.65\n",
      "Accuracy of NN regressor on test set: 0.68\n",
      "\n",
      "Accuracy of NN regressor with activation funtion = tanh and alpha = 1.0 on training set: 0.65\n",
      "Accuracy of NN regressor on test set: 0.68\n",
      "\n",
      "Accuracy of NN regressor with activation funtion = tanh and alpha = 100 on training set: 0.65\n",
      "Accuracy of NN regressor on test set: 0.68\n",
      "\n",
      "Accuracy of NN regressor with activation funtion = relu and alpha = 0.0001 on training set: 0.65\n",
      "Accuracy of NN regressor on test set: 0.68\n",
      "\n",
      "Accuracy of NN regressor with activation funtion = relu and alpha = 1.0 on training set: 0.65\n",
      "Accuracy of NN regressor on test set: 0.68\n",
      "\n",
      "Accuracy of NN regressor with activation funtion = relu and alpha = 100 on training set: 0.65\n",
      "Accuracy of NN regressor on test set: 0.68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "# normalized\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Accuracy with different activation functions and regularization parameter alpha\n",
    "for thisactivation in ['tanh', 'relu']:\n",
    "    for thisalpha in [0.0001, 1.0, 100]:\n",
    "        mlpreg = MLPRegressor(hidden_layer_sizes = [100,100],\n",
    "                             activation = thisactivation,\n",
    "                             alpha = thisalpha,\n",
    "                             solver = 'lbfgs').fit(X_train, y_train)\n",
    "        print('Accuracy of NN regressor with activation funtion = {} and alpha = {} on training set: {:.2f}'.format(thisactivation, thisalpha, clf.score(X_train_scaled, y_train)))\n",
    "        print('Accuracy of NN regressor on test set: {:.2f}\\n'.format(clf.score(X_test_scaled, y_test)))\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
